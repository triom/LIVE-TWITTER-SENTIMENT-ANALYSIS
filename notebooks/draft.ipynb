{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learning\\LIVE-TWITTER-SENTIMENT-ANALYSIS\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>julie81</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>richardhester</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williamsjoseph</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>danielsmary</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>carlwarren</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID        Username  \\\n",
       "0         1         julie81   \n",
       "1         2   richardhester   \n",
       "2         3  williamsjoseph   \n",
       "3         4     danielsmary   \n",
       "4         5      carlwarren   \n",
       "\n",
       "                                                Text  Retweets  Likes  \\\n",
       "0  Party least receive say or single. Prevent pre...         2     25   \n",
       "1  Hotel still Congress may member staff. Media d...        35     29   \n",
       "2  Nice be her debate industry that year. Film wh...        51     25   \n",
       "3  Laugh explain situation career occur serious. ...        37     18   \n",
       "4  Involve sense former often approach government...        27     80   \n",
       "\n",
       "             Timestamp  \n",
       "0  2023-01-30 11:00:51  \n",
       "1  2023-01-02 22:45:58  \n",
       "2  2023-01-18 11:25:19  \n",
       "3  2023-04-10 22:06:29  \n",
       "4  2023-01-24 07:12:21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('twitter_dataset.csv') \n",
    "df1[\"Text\"] = df1[\"Text\"].astype(str)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df1['Timestamp'] = df1['Timestamp'].dt.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "df1 = df1.drop(columns=[\"Username\", \"Retweets\", \"Tweet_ID\"])\n",
    "df1.rename(columns={'Text': 'text', 'Timestamp':'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>25</td>\n",
       "      <td>30-01-2023 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>29</td>\n",
       "      <td>02-01-2023 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>25</td>\n",
       "      <td>18-01-2023 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>18</td>\n",
       "      <td>10-04-2023 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>80</td>\n",
       "      <td>24-01-2023 07:12:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Likes  \\\n",
       "0  Party least receive say or single. Prevent pre...     25   \n",
       "1  Hotel still Congress may member staff. Media d...     29   \n",
       "2  Nice be her debate industry that year. Film wh...     25   \n",
       "3  Laugh explain situation career occur serious. ...     18   \n",
       "4  Involve sense former often approach government...     80   \n",
       "\n",
       "                  date  \n",
       "0  30-01-2023 11:00:51  \n",
       "1  02-01-2023 22:45:58  \n",
       "2  18-01-2023 11:25:19  \n",
       "3  10-04-2023 22:06:29  \n",
       "4  24-01-2023 07:12:21  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-05 17:55:09+00:00</td>\n",
       "      <td>@BillyM2k I find the gold toe sock – inevitabl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-05 17:47:42+00:00</td>\n",
       "      <td>Sock Con, the conference for socks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-05 17:46:15+00:00</td>\n",
       "      <td>Always something new for the magazine cover an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-05 17:40:05+00:00</td>\n",
       "      <td>@ExplainThisBob This guy gets it</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-05 17:38:23+00:00</td>\n",
       "      <td>Sock tech is so advanced that you can get pret...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03 23:48:42+00:00</td>\n",
       "      <td>@JonErlichman He’s not wrong …</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03 23:31:23+00:00</td>\n",
       "      <td>@alifarhat79 Guys, I think I maybe took too mu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03 23:23:41+00:00</td>\n",
       "      <td>@sriramk Cool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03 22:59:31+00:00</td>\n",
       "      <td>@cb_doge Time to complete the circle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03 22:21:29+00:00</td>\n",
       "      <td>@Jason Late stage civilization complacency</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5904 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_location                       date  \\\n",
       "0              NaN  2022-07-05 17:55:09+00:00   \n",
       "1              NaN  2022-07-05 17:47:42+00:00   \n",
       "2              NaN  2022-07-05 17:46:15+00:00   \n",
       "3              NaN  2022-07-05 17:40:05+00:00   \n",
       "4              NaN  2022-07-05 17:38:23+00:00   \n",
       "...            ...                        ...   \n",
       "5899           NaN  2023-06-03 23:48:42+00:00   \n",
       "5900           NaN  2023-06-03 23:31:23+00:00   \n",
       "5901           NaN  2023-06-03 23:23:41+00:00   \n",
       "5902           NaN  2023-06-03 22:59:31+00:00   \n",
       "5903           NaN  2023-06-03 22:21:29+00:00   \n",
       "\n",
       "                                                   text hashtags  \n",
       "0     @BillyM2k I find the gold toe sock – inevitabl...      NaN  \n",
       "1                    Sock Con, the conference for socks      NaN  \n",
       "2     Always something new for the magazine cover an...      NaN  \n",
       "3                      @ExplainThisBob This guy gets it      NaN  \n",
       "4     Sock tech is so advanced that you can get pret...      NaN  \n",
       "...                                                 ...      ...  \n",
       "5899                     @JonErlichman He’s not wrong …      NaN  \n",
       "5900  @alifarhat79 Guys, I think I maybe took too mu...      NaN  \n",
       "5901                                      @sriramk Cool      NaN  \n",
       "5902               @cb_doge Time to complete the circle      NaN  \n",
       "5903         @Jason Late stage civilization complacency      NaN  \n",
       "\n",
       "[5904 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('elon_musk_tweets.csv')\n",
    "df2 = df2.drop(columns=[\"id\",\"user_name\",\"user_description\",\"user_created\",\"user_followers\",\"user_friends\",\"user_favourites\",\"user_verified\",\"source\", \"retweets\", \"favorites\",\"is_retweet\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astroworld</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_location                 date  \\\n",
       "0            astroworld  2020-07-25 12:27:21   \n",
       "1          New York, NY  2020-07-25 12:27:17   \n",
       "2      Pewee Valley, KY  2020-07-25 12:27:14   \n",
       "3  Stuck in the Middle   2020-07-25 12:27:10   \n",
       "4     Jammu and Kashmir  2020-07-25 12:27:08   \n",
       "\n",
       "                                                text  \\\n",
       "0  If I smelled the scent of hand sanitizers toda...   \n",
       "1  Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2  @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3  @brookbanktv The one gift #COVID19 has give me...   \n",
       "4  25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "\n",
       "                            hashtags  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2                        ['COVID19']  \n",
       "3                        ['COVID19']  \n",
       "4  ['CoronaVirusUpdates', 'COVID19']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('covid19_tweets.csv')\n",
    "df3 = df3.drop(columns=[\"user_name\",\"user_description\",\"user_created\",\"user_followers\",\"user_friends\",\"user_favourites\",\"user_verified\",\"source\", \"is_retweet\"])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# data cleaning and prep\n",
    "def data_cleaning_and_preparation(df, text_column):\n",
    "    # 1. Drop rows with missing values in text columns\n",
    "    df.dropna(subset=[text_column], inplace=True)\n",
    "\n",
    "    # 2. Remove duplicates\n",
    "    df.drop_duplicates(subset=[text_column], inplace=True)\n",
    "\n",
    "    # 3. Convert text to lowercase\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "    # 4. Remove special characters, punctuation, and numimbers\n",
    "    df[text_column] = df[text_column].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "    # 5. Remove extra whitespace\n",
    "    df[text_column] = df[text_column].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "    # 7. Check the cleaned data\n",
    "    print(df.head())\n",
    "    return df\n",
    "    # Save the cleaned text data\n",
    "    # df.to_csv('cleaned_text_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_cleaning_and_preparation(df1, text_column='text')\n",
    "df2 = data_cleaning_and_preparation(df2, text_column='text')\n",
    "df3 = data_cleaning_and_preparation(df3, text_column='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.concat([df1,df2, df3], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [df1, df2, df3]\n",
    "non_empty_dfs = [df for df in dfs if df is not None and not df.empty]\n",
    "\n",
    "# Concatenate the remaining valid DataFrames\n",
    "if non_empty_dfs:\n",
    "    result = pd.concat(non_empty_dfs, axis=1)\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"No valid DataFrames to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)\n",
    "result.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.iloc[: cutting_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_transformers(df):\n",
    "    \n",
    "    model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\"\n",
    "    analyser = pipeline(\"sentiment-analysis\", model=model_path)\n",
    "    df['scores'] = df['Text'].apply(lambda text: analyser (text.lower()))\n",
    "    df['Sentiment'] = df['scores'].apply(lambda output: output[0]['label']) \n",
    "    df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == 'positive' else (-1 if x == 'negative' else 0)) \n",
    "    \n",
    "    # df['Sentiment'] = df['Sentiment'].apply(lambda x: 'Positive' if x == 'positive' else ('Negative' if x == 'negative' else 'Neutral')) \n",
    "    \n",
    "    # df['Sentiment'] = df['Sentiment'].apply(lambda x: 'Positive ❤️' if x == 'positive' else ('Negative 😡' if x == 'negative' else 'Neutral 💛')) \n",
    "    \n",
    "    df =  df.drop(columns = [\"scores\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_result = sentiment_analysis_transformers(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>30-01-2023 11:00:51</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>02-01-2023 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>18-01-2023 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>10-04-2023 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>24-01-2023 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Make environment actually feeling hit need. Be...</td>\n",
       "      <td>29-01-2023 05:36:17</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Just him investment state her either trial. Fo...</td>\n",
       "      <td>20-01-2023 13:10:51</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Similar also finish analysis.\\nIndividual bene...</td>\n",
       "      <td>12-04-2023 09:51:11</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Possible resource early itself head federal. T...</td>\n",
       "      <td>28-03-2023 03:02:53</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>News generation worker yourself minute lot. Ne...</td>\n",
       "      <td>09-02-2023 03:39:32</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_ID                                               Text  \\\n",
       "0           1  Party least receive say or single. Prevent pre...   \n",
       "1           2  Hotel still Congress may member staff. Media d...   \n",
       "2           3  Nice be her debate industry that year. Film wh...   \n",
       "3           4  Laugh explain situation career occur serious. ...   \n",
       "4           5  Involve sense former often approach government...   \n",
       "..        ...                                                ...   \n",
       "995       996  Make environment actually feeling hit need. Be...   \n",
       "996       997  Just him investment state her either trial. Fo...   \n",
       "997       998  Similar also finish analysis.\\nIndividual bene...   \n",
       "998       999  Possible resource early itself head federal. T...   \n",
       "999      1000  News generation worker yourself minute lot. Ne...   \n",
       "\n",
       "               Timestamp Sentiment  \n",
       "0    30-01-2023 11:00:51  Positive  \n",
       "1    02-01-2023 22:45:58   Neutral  \n",
       "2    18-01-2023 11:25:19  Positive  \n",
       "3    10-04-2023 22:06:29   Neutral  \n",
       "4    24-01-2023 07:12:21   Neutral  \n",
       "..                   ...       ...  \n",
       "995  29-01-2023 05:36:17   Neutral  \n",
       "996  20-01-2023 13:10:51   Neutral  \n",
       "997  12-04-2023 09:51:11   Neutral  \n",
       "998  28-03-2023 03:02:53   Neutral  \n",
       "999  09-02-2023 03:39:32  Positive  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised “minimum government maximum...      -1.0\n",
       "1       talk all the nonsense and continue all the dra...       0.0\n",
       "2       what did just say vote for modi  welcome bjp t...       1.0\n",
       "3       asking his supporters prefix chowkidar their n...       1.0\n",
       "4       answer who among these the most powerful world...       1.0\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "162977  did you cover her interaction forum where she ...       0.0\n",
       "162978  there big project came into india modi dream p...       0.0\n",
       "162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('Twitter_Data.csv') \n",
    "df2[\"clean_text\"] = df2[\"clean_text\"].astype(str)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df2.iloc[:cutting_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis1(df):\n",
    "    \n",
    "    model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\"\n",
    "    analyser = pipeline(\"sentiment-analysis\", model=model_path)\n",
    "    df['scores'] = df['clean_text'].apply(lambda text: analyser (text.lower()))\n",
    "    df['Sentiment'] = df['scores'].apply(lambda output: output[0]['label']) \n",
    "    df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == 'positive' else (-1 if x == 'negative' else 0)) \n",
    "    \n",
    "    df =  df.drop(columns = [\"scores\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = sentiment_analysis1(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[170  38  17]\n",
      " [125 130  79]\n",
      " [182  93 166]]\n",
      "\n",
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.36      0.76      0.48       225\n",
      "         0.0       0.50      0.39      0.44       334\n",
      "         1.0       0.63      0.38      0.47       441\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.50      0.51      0.46      1000\n",
      "weighted avg       0.53      0.47      0.46      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_result[\"category\"], test_result[\"Sentiment\"])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = classification_report(test_result[\"category\"], test_result[\"Sentiment\"])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beaut\\AppData\\Local\\Temp\\ipykernel_24748\\767759645.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Sentiment'] = data['clean_text'].apply(classify_sentiment)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>another meltdown india which will further rejo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>there are two reasons for atmosphere hatred cr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>modi has wiped out the small micro industries ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>bjp struggles find candidates west bengal graf...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>modis opposition trying defame him they not wa...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  category  Sentiment\n",
       "0    when modi promised “minimum government maximum...      -1.0          0\n",
       "1    talk all the nonsense and continue all the dra...       0.0          0\n",
       "2    what did just say vote for modi  welcome bjp t...       1.0          0\n",
       "3    asking his supporters prefix chowkidar their n...       1.0          0\n",
       "4    answer who among these the most powerful world...       1.0          0\n",
       "..                                                 ...       ...        ...\n",
       "995  another meltdown india which will further rejo...       1.0          0\n",
       "996  there are two reasons for atmosphere hatred cr...       0.0          0\n",
       "997  modi has wiped out the small micro industries ...      -1.0          0\n",
       "998  bjp struggles find candidates west bengal graf...      -1.0          0\n",
       "999  modis opposition trying defame him they not wa...      -1.0          0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your CSV file\n",
    "data = test_data\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to analyze sentiment and classify based on compound score\n",
    "def classify_sentiment(text):\n",
    "    # Get sentiment scores\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    \n",
    "    # Get individual scores\n",
    "    neg_score = scores['neg']\n",
    "    neu_score = scores['neu']\n",
    "    pos_score = scores['pos']\n",
    "    compound_score = scores['compound']\n",
    "    \n",
    "    # Check if compound score is the highest\n",
    "    if compound_score >= max(neg_score, neu_score, pos_score):\n",
    "        # Classify based on compound score\n",
    "        if compound_score >= 0.05:\n",
    "            return 1\n",
    "        elif compound_score > -0.05:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        # Classify based on the highest individual score\n",
    "        highest_score = max(neg_score, neu_score, pos_score)\n",
    "        if highest_score == neg_score:\n",
    "            return -1\n",
    "        elif highest_score == neu_score:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "text = \"This movie was okay, not great but not terrible\"\n",
    "print(classify_sentiment(text))\n",
    "\n",
    "# # Apply the sentiment analysis function to the 'text' column\n",
    "data['Sentiment'] = data['clean_text'].apply(classify_sentiment)\n",
    "data = data.drop(columns=[\"scores\"])\n",
    "# data['Sentiment'] = data['Text'].apply(classify_sentiment)\n",
    "data\n",
    "# Save the results to a new CSV file\n",
    "# data.to_csv('data_with_sentiment.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  9 201  15]\n",
      " [  2 309  23]\n",
      " [  1 341  99]]\n",
      "\n",
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.75      0.04      0.08       225\n",
      "         0.0       0.36      0.93      0.52       334\n",
      "         1.0       0.72      0.22      0.34       441\n",
      "\n",
      "    accuracy                           0.42      1000\n",
      "   macro avg       0.61      0.40      0.31      1000\n",
      "weighted avg       0.61      0.42      0.34      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(data[\"category\"], data[\"Sentiment\"])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = classification_report(data[\"category\"], data[\"Sentiment\"])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load CSV file\n",
    "# data = pd.read_csv('data.csv')\n",
    "data_gpt  = test_data.loc[:100]\n",
    "\n",
    "# Function to analyze sentiment\n",
    "def analyze_sentiment(text):\n",
    "    prompt = f\"What is the sentiment of the following text? '{text}'\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=100, do_sample=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply sentiment analysis to each row in the 'text' column\n",
    "data_gpt['Sentiment'] = data['clean_text'].apply(analyze_sentiment)\n",
    "\n",
    "# # Save the results to a new CSV file\n",
    "# data.to_csv('data_with_sentiment.csv', index=False)\n",
    "\n",
    "# print(\"Sentiment analysis complete! Results saved to 'data_with_sentiment.csv'.\")\n",
    "# print(analyze_sentiment(text))\n",
    "data_gpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(data_gpt[\"category\"], data_gpt[\"Sentiment\"])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = classification_report(data_gpt[\"category\"], data_gpt[\"Sentiment\"])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag gen\n",
    "# topic classififcation\n",
    "# data cleaning and enreichement\n",
    "# define the terms of the projet ie\n",
    "# sentiment anal, ETL, pipeline, real time, batch,diragrams, usecase, class, package,sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\beaut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shopping', 'Food', 'Foodies']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fabiochiu/t5-base-tag-generation\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"fabiochiu/t5-base-tag-generation\")\n",
    "def hastag_generator(text):\n",
    "\n",
    "    inputs = tokenizer([text], max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10,\n",
    "                            max_length=64)\n",
    "    decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    tags = list(set(decoded_output.strip().split(\", \")))\n",
    "\n",
    "    return tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
